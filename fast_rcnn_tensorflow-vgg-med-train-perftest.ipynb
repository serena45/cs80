{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from matplotlib import patches\n",
    "from random import shuffle, randint\n",
    "\n",
    "import selectivesearch\n",
    "import skimage.data\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipython_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing IPython notebook from roi_pooling_importer.ipynb\n",
      "importing IPython notebook from VOC_import.ipynb\n"
     ]
    }
   ],
   "source": [
    "from roi_pooling_importer import import_roi_pooling_op\n",
    "import VOC_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roi_pooling_op_dir = os.getenv(\"HOME\") + \"/packages/tensorflow/bazel-bin/tensorflow/core/user_ops/\"\n",
    "roi_pooling_op = import_roi_pooling_op(roi_pooling_op_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This will be trained with BGR images with pixels in range [-255, 255]\n",
    "# Takes a list of ROIs. Currently only handles one image at a time. \n",
    "# ROIs must be scaled with roi_scaling factor before input\n",
    "\n",
    "# The width and height of the image\n",
    "image_size = 224 # Must be divisible by the pooling layers\n",
    "\n",
    "# Image depth\n",
    "image_depth = 3\n",
    "\n",
    "# The batch size\n",
    "batch_size = 1\n",
    "\n",
    "# number of classes\n",
    "num_classes = 20\n",
    "num_classes_with_background = num_classes + 1\n",
    "\n",
    "# The number of region proposals\n",
    "#num_rois = 200\n",
    "\n",
    "# The scaling factor for ROIs - equivalent to the combined downsampling of all prior strided accesses\n",
    "# 4 (conv1) * 2 (pool1) * 2 (pool2) = 16\n",
    "roi_scaling = 16\n",
    "\n",
    "# Pixel means (probably for PASCAL VOC?) in BGR order\n",
    "pixel_means = np.array([[[102.9801, 115.9465, 122.7717]]])\n",
    "\n",
    "# Device to use\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: background examples\n",
    "# TODO: fix data ordering to NCHW\n",
    "# TODO look at graph output in visualizer to make sure it looks right\n",
    "# TODO fix the default initializations of weights and biases if we want to train\n",
    "# TODO add dropout\n",
    "# TODO add weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters to think about tweaking:\n",
    "# LRU: k, alpha, beta\n",
    "# Inputs: input image normalization, background examples, etc\n",
    "# Data ordering: NCHW vs NHWC\n",
    "# Outputs: add bounding box regression\n",
    "# Weights: initial values\n",
    "# Dropout, weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions for defining networks\n",
    "def weight_variable(shape, wd):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    weight_decay = tf.mul(tf.nn.l2_loss(initial), wd)\n",
    "    tf.add_to_collection('losses', weight_decay)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def max_pool(x, kernel_size, stride):\n",
    "    return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1],\n",
    "                        strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def local_response_normalization(x):\n",
    "    # TODO is 5 the correct radius?\n",
    "    return tf.nn.local_response_normalization(x, depth_radius=5, alpha=.0001, beta=.75, bias=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Something like Alexnet\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(\n",
    "    allow_soft_placement=True, log_device_placement=True))\n",
    "\n",
    "with tf.device(\"/{}:0\".format(device)):\n",
    "    \n",
    "    # Batched input\n",
    "    input_data_tensor = tf.placeholder(tf.float32, shape=[None, image_size, image_size, image_depth], name=\"Input_Image_Batch\") # batch size, image size, image size, image depth\n",
    "    y_ = tf.placeholder(tf.int32, shape=[None], name=\"Input_Classes\") # index of the correct class for each ROI\n",
    "    rois_in = tf.placeholder(tf.int32, shape=[None, 4], name=\"Input_ROIs\")\n",
    "    rois = tf.reshape(rois_in, [1, -1, 4])\n",
    "\n",
    "    # First Convolutional Layer\n",
    "    # Variables\n",
    "    W_conv1 = weight_variable([7, 7, image_depth, 96], wd=0.0) # filter size, filter size, input channels (image depth), output channels\n",
    "    b_conv1 = bias_variable([96])\n",
    "    # Layers\n",
    "    conv1 = conv2d(input_data_tensor, W_conv1, stride=2)\n",
    "    relu1 = tf.nn.relu(conv1 + b_conv1)\n",
    "    norm1 = local_response_normalization(relu1)\n",
    "    pool1 = max_pool(norm1, kernel_size=3, stride=2)\n",
    "\n",
    "    # Second Convolutional Layer\n",
    "    # Variables\n",
    "    W_conv2 = weight_variable([5, 5, 96, 256], wd=0.0) # filter size, filter size, input channels (image depth), output channels\n",
    "    b_conv2 = bias_variable([256])\n",
    "    # Layers\n",
    "    conv2 = conv2d(pool1, W_conv2, stride=2)\n",
    "    relu2 = tf.nn.relu(conv2 + b_conv2)\n",
    "    # error was here\n",
    "    norm2 = local_response_normalization(relu2)\n",
    "    pool2 = max_pool(norm2, kernel_size=3, stride=2)\n",
    "\n",
    "    # Third Convolutional Layer\n",
    "    # Variables\n",
    "    W_conv3 = weight_variable([3, 3, 256, 512], wd=0.0) # filter size, filter size, input channels (image depth), output channels\n",
    "    b_conv3 = bias_variable([512])\n",
    "    # Layers\n",
    "    conv3 = conv2d(pool2, W_conv3, stride=1)\n",
    "    relu3 = tf.nn.relu(conv3 + b_conv3)\n",
    "\n",
    "    # Fourth Convolutional Layer\n",
    "    # Variables\n",
    "    # Variables\n",
    "    W_conv4 = weight_variable([3, 3, 512, 512], wd=0.0) # filter size, filter size, input channels (image depth), output channels\n",
    "    b_conv4 = bias_variable([512])\n",
    "    # Layers\n",
    "    conv4 = conv2d(relu3, W_conv4, stride=1)\n",
    "    relu4 = tf.nn.relu(conv4 + b_conv4)\n",
    "\n",
    "    # Fifth Convolutional Layer\n",
    "    # Variables\n",
    "    W_conv5 = weight_variable([3, 3, 512, 512], wd=0.0) # filter size, filter size, input channels (image depth), output channels\n",
    "    b_conv5 = bias_variable([512])\n",
    "    # Layers\n",
    "    conv5 = conv2d(relu4, W_conv5, stride=1)\n",
    "    relu5 = tf.nn.relu(conv5 + b_conv5)\n",
    "\n",
    "    # ROI pooling to an output feature map of 6x6\n",
    "    # Convert NHWC to NCHW\n",
    "    relu5_transpose = tf.transpose(relu5, [0, 3, 1, 2])\n",
    "    output_dim_tensor = tf.constant((6,6))\n",
    "    roi_pool5, argmax = roi_pooling_op(relu5_transpose, rois, output_dim_tensor)\n",
    "\n",
    "    # ROI pooling outputs in NCRHW. Not sure what FC is expecting. \n",
    "    # Caffe layer appears to do NRCHW. Not sure about NR vs RN, but doesn't matter for single image.\n",
    "    roi_pool5_transpose = tf.transpose(roi_pool5, [0, 2, 1, 3, 4])\n",
    "    \n",
    "    # We need to bring this down to 4-d - collapse the ROI and batch together somehow.\n",
    "    # Should be redundant with next reshape, but whatever\n",
    "    roi_pool5_reshaped = tf.reshape(roi_pool5_transpose, (-1, 512, 6, 6))\n",
    "\n",
    "    # Fully Connected 1\n",
    "    # Weights\n",
    "    # Weight variable is sized to match num_rois * roi_pooling_feature_length (6 x 6)\n",
    "    W_fc6 = weight_variable([512 * 6 * 6, 4096], wd=0.0)\n",
    "    b_fc6 = bias_variable([4096])\n",
    "    # Layers\n",
    "    roi_pool5_flat = tf.reshape(roi_pool5_reshaped, [-1, 6 * 6 * 512])\n",
    "    fc6 = tf.matmul(roi_pool5_flat, W_fc6)\n",
    "    relu6 = tf.nn.relu(fc6 + b_fc6)\n",
    "\n",
    "    # TODO dropout if we want to train\n",
    "\n",
    "    # Fully Connected 2\n",
    "    # Weights\n",
    "    W_fc7 = weight_variable([4096, 1024], wd=0.004)\n",
    "    b_fc7 = bias_variable([1024])\n",
    "    # Layers\n",
    "    fc7 = tf.matmul(relu6, W_fc7)\n",
    "    relu7 = tf.nn.relu(fc7 + b_fc7)\n",
    "\n",
    "    # TODO dropout if we want to train\n",
    "\n",
    "\n",
    "    # Classification Score\n",
    "    # Weights\n",
    "    W_cls = weight_variable([1024, num_classes_with_background], wd=0.0)\n",
    "    b_cls = bias_variable([num_classes_with_background])\n",
    "    # Layers\n",
    "    cls_score = tf.matmul(relu7, W_cls) + b_cls\n",
    "    cls_prob=tf.nn.softmax(cls_score)\n",
    "    \n",
    "    # Loss function\n",
    "    # Cross entropy. Note - inputs are unscaled (not softmax output). y_'s are indexes, not vectors\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(cls_score, y_, name=None)\n",
    "    cross_entropy_loss = tf.nn.l2_loss(cross_entropy)\n",
    "    \n",
    "    # Optimizer\n",
    "    learning_rate_tf = tf.placeholder(tf.float32)\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate_tf)\n",
    "    \n",
    "    # Minimize wrt specified variables. If var_list not specified, uses all variables?\n",
    "    variables_to_optimize = [W_cls, b_cls, W_fc7, b_fc7, W_fc6, b_fc6]\n",
    "    opt_top_op = opt.minimize(cross_entropy_loss, var_list=variables_to_optimize)\n",
    "    opt_all_op = opt.minimize(cross_entropy_loss)\n",
    "    \n",
    "    # Evaluation\n",
    "    num_rois_tf = tf.placeholder(tf.float32)\n",
    "    top_k = tf.nn.in_top_k(cls_score, y_, 3)\n",
    "    top_k_sum = tf.reduce_sum(tf.cast(top_k, tf.float32))\n",
    "    top_k_percent = tf.div(top_k_sum, num_rois_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/{}:0\".format(device)):\n",
    "    sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imported_weights = np.load(\"model_med.numpy\", fix_imports=True, encoding=\"bytes\").tolist()\n",
    "\n",
    "with tf.device(\"/{}:0\".format(device)):\n",
    "    assign_ops = []\n",
    "    # Not sure what b prefix on string does.. seems necessary tho\n",
    "    assign_ops.append(W_conv1.assign(imported_weights[\"conv1\"][b\"weights\"]))\n",
    "    assign_ops.append(b_conv1.assign(imported_weights[\"conv1\"][b\"biases\"]))\n",
    "    assign_ops.append(W_conv2.assign(imported_weights[\"conv2\"][b\"weights\"]))\n",
    "    assign_ops.append(b_conv2.assign(imported_weights[\"conv2\"][b\"biases\"]))\n",
    "    assign_ops.append(W_conv3.assign(imported_weights[\"conv3\"][b\"weights\"]))\n",
    "    assign_ops.append(b_conv3.assign(imported_weights[\"conv3\"][b\"biases\"]))\n",
    "    assign_ops.append(W_conv4.assign(imported_weights[\"conv4\"][b\"weights\"]))\n",
    "    assign_ops.append(b_conv4.assign(imported_weights[\"conv4\"][b\"biases\"]))\n",
    "    assign_ops.append(W_conv5.assign(imported_weights[\"conv5\"][b\"weights\"]))\n",
    "    assign_ops.append(b_conv5.assign(imported_weights[\"conv5\"][b\"biases\"]))\n",
    "\n",
    "    #assign_ops.append(W_fc6.assign(imported_weights[\"fc6\"][b\"weights\"]))\n",
    "    #assign_ops.append(b_fc6.assign(imported_weights[\"fc6\"][b\"biases\"]))\n",
    "    #assign_ops.append(W_fc7.assign(imported_weights[\"fc7\"][b\"weights\"]))\n",
    "    #assign_ops.append(b_fc7.assign(imported_weights[\"fc7\"][b\"biases\"]))\n",
    "\n",
    "    #assign_ops.append(W_cls.assign(imported_weights[\"cls_score\"][b\"weights\"]))\n",
    "    #assign_ops.append(b_cls.assign(imported_weights[\"cls_score\"][b\"biases\"]))\n",
    "\n",
    "    for op in assign_ops:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runningMeanFast(x, N):\n",
    "    return np.convolve(x, np.ones((N,))/N)[(N-1):]\n",
    "\n",
    "def get_inputs(sample_type):\n",
    "    if sample_type == \"train\":\n",
    "        img, roi = next(train_sample_generator)\n",
    "    else:\n",
    "        img, roi = next(test_sample_generator)\n",
    "    \n",
    "    input_data = img.reshape(batch_size, image_size, image_size, image_depth)\n",
    "    input_rois = np.asarray(roi[0]).reshape(len(roi[0]), 4)\n",
    "    # Scale ROIs to pooled size\n",
    "    input_rois = (input_rois / roi_scaling).astype(np.int32)\n",
    "    input_classes = np.asarray(roi[1])\n",
    "    \n",
    "    return input_data, input_rois, input_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = []\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sample_generator = VOC_import.get_train_sample()\n",
    "test_sample_generator = VOC_import.get_val_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#opt_op = opt_all_op\n",
    "opt_op = opt_top_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.906250476837158\n"
     ]
    }
   ],
   "source": [
    "train_sample_generator = VOC_import.get_train_sample()\n",
    "test_sample_generator = VOC_import.get_val_sample()\n",
    "\n",
    "\n",
    "clk = time.time()\n",
    "input_data = np.random.random((1, 224, 224, 3)).astype(np.float32)\n",
    "input_rois = np.zeros((200,4))\n",
    "\n",
    "for x in range(100):\n",
    "    learning_rate = .00008\n",
    "    \n",
    "    with tf.device(\"/{}:0\".format(device)):\n",
    "        sess.run(relu5, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                     rois_in:input_rois, num_rois_tf:len(input_rois)})\n",
    "\n",
    "    \n",
    "    \n",
    "    i += 1\n",
    "print(time.time() - clk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1851153373718262\n"
     ]
    }
   ],
   "source": [
    "train_sample_generator = VOC_import.get_train_sample()\n",
    "test_sample_generator = VOC_import.get_val_sample()\n",
    "clk = time.time()\n",
    "\n",
    "\n",
    "input_data = np.random.random((1, 224, 224, 3)).astype(np.float32)\n",
    "input_rois = np.zeros((1,4))\n",
    "\n",
    "for x in range(25):\n",
    "    learning_rate = .00008\n",
    "\n",
    " \n",
    "    \n",
    "    with tf.device(\"/{}:0\".format(device)):\n",
    "        sess.run(roi_pool5_reshaped, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                     rois_in:input_rois, num_rois_tf:len(input_rois)})\n",
    "\n",
    "    \n",
    "    \n",
    "    i += 1\n",
    "print(time.time() - clk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cls_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-fedb5b1d89fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/{}:0\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         sess.run(cls_prob, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n\u001b[1;32m---> 14\u001b[1;33m                                      rois_in:input_rois, num_rois_tf:len(input_rois)})\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 333\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    334\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 573\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 648\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    649\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    653\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    636\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sample_generator = VOC_import.get_train_sample()\n",
    "test_sample_generator = VOC_import.get_val_sample()\n",
    "clk = time.time()\n",
    "\n",
    "input_data = np.random.random((1, 224, 224, 3)).astype(np.float32)\n",
    "input_rois = np.zeros((200,4))\n",
    "\n",
    "for x in range(100):\n",
    "    learning_rate = .00008\n",
    "\n",
    "\n",
    "    with tf.device(\"/{}:0\".format(device)):\n",
    "        sess.run(cls_prob, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                     rois_in:input_rois, num_rois_tf:len(input_rois)})\n",
    "\n",
    "    \n",
    "    \n",
    "    i += 1\n",
    "print(time.time() - clk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sample_generator = VOC_import.get_train_sample()\n",
    "test_sample_generator = VOC_import.get_val_sample()\n",
    "clk = time.time()\n",
    "\n",
    "input_data = np.random.random((1, 224, 224, 3)).astype(np.float32)\n",
    "input_rois = np.zeros((1,4))\n",
    "\n",
    "for x in range(100):\n",
    "    learning_rate = .00008\n",
    "\n",
    "\n",
    "    with tf.device(\"/{}:0\".format(device)):\n",
    "        sess.run(cls_prob, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                    rois_in:input_rois, num_rois_tf:len(input_rois)})\n",
    "\n",
    "    \n",
    "    \n",
    "    i += 1\n",
    "print(time.time() - clk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iterations took 0.20767712593078613\n",
      "11 iterations took 0.19229388236999512\n",
      "21 iterations took 0.21101117134094238\n",
      "31 iterations took 0.20078778266906738\n",
      "41 iterations took 0.24199914932250977\n",
      "51 iterations took 0.22094297409057617\n",
      "61 iterations took 0.18572378158569336\n",
      "71 iterations took 0.18959951400756836\n",
      "81 iterations took 0.1825709342956543\n",
      "91 iterations took 0.18865561485290527\n",
      "101 iterations took 0.18597960472106934\n",
      "111 iterations took 0.18651247024536133\n",
      "121 iterations took 0.1845870018005371\n",
      "131 iterations took 0.19179129600524902\n",
      "141 iterations took 0.18169927597045898\n",
      "151 iterations took 0.18555402755737305\n",
      "161 iterations took 0.18239450454711914\n",
      "171 iterations took 0.188079833984375\n",
      "181 iterations took 0.18012762069702148\n",
      "191 iterations took 0.1884005069732666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d525333e3278>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/{}:0\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             sess.run(relu5, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n\u001b[1;32m---> 19\u001b[1;33m                                         rois_in:input_rois, num_rois_tf:len(input_rois)})\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 333\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    334\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 573\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 648\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    649\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    653\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/zack/packages/tensorflow/_python_build/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    636\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sample_generator = VOC_import.get_train_sample()\n",
    "test_sample_generator = VOC_import.get_val_sample()\n",
    "\n",
    "times = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 500, 10):\n",
    "    clk = time.time()\n",
    "    input_data = np.random.random((1, 224, 224, 3)).astype(np.float32)\n",
    "    input_rois = np.zeros((i,4))\n",
    "\n",
    "    for x in range(5):\n",
    "        learning_rate = .00008\n",
    "\n",
    "\n",
    "        with tf.device(\"/{}:0\".format(device)):\n",
    "            sess.run(relu5, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                        rois_in:input_rois, num_rois_tf:len(input_rois)})\n",
    "\n",
    "\n",
    "\n",
    "    dt = time.time() - clk\n",
    "    print(\"{} iterations took {}\".format( i, dt ))\n",
    "    times.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, 500, 10), times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iterations took 0.07808828353881836\n",
      "11 iterations took 0.14977312088012695\n",
      "21 iterations took 0.20688557624816895\n",
      "31 iterations took 0.2885770797729492\n",
      "41 iterations took 0.4523484706878662\n",
      "51 iterations took 0.43332910537719727\n",
      "61 iterations took 0.47906923294067383\n",
      "71 iterations took 0.5883502960205078\n",
      "81 iterations took 0.6316263675689697\n",
      "91 iterations took 0.6847646236419678\n",
      "101 iterations took 0.8035049438476562\n",
      "111 iterations took 0.8308851718902588\n",
      "121 iterations took 0.9043624401092529\n",
      "131 iterations took 1.0022730827331543\n",
      "141 iterations took 1.0630385875701904\n",
      "151 iterations took 1.1064717769622803\n",
      "161 iterations took 1.1693615913391113\n",
      "171 iterations took 1.2916560173034668\n",
      "181 iterations took 1.3341889381408691\n",
      "191 iterations took 1.3858215808868408\n",
      "201 iterations took 1.4564826488494873\n",
      "211 iterations took 1.5332489013671875\n",
      "221 iterations took 1.7846779823303223\n",
      "231 iterations took 1.6952788829803467\n",
      "241 iterations took 1.7555346488952637\n",
      "251 iterations took 1.8356547355651855\n",
      "261 iterations took 2.047079086303711\n",
      "271 iterations took 2.2249338626861572\n",
      "281 iterations took 2.2579474449157715\n",
      "291 iterations took 2.4697442054748535\n",
      "301 iterations took 2.159334659576416\n",
      "311 iterations took 2.220510959625244\n",
      "321 iterations took 2.377876043319702\n",
      "331 iterations took 2.3909897804260254\n",
      "341 iterations took 2.5081944465637207\n",
      "351 iterations took 2.5745725631713867\n",
      "361 iterations took 2.5827250480651855\n",
      "371 iterations took 2.666656494140625\n",
      "381 iterations took 2.739008665084839\n",
      "391 iterations took 2.7880587577819824\n",
      "401 iterations took 2.8510942459106445\n",
      "411 iterations took 3.0180106163024902\n",
      "421 iterations took 3.1643459796905518\n",
      "431 iterations took 3.1064603328704834\n",
      "441 iterations took 3.160381317138672\n",
      "451 iterations took 3.293875217437744\n",
      "461 iterations took 3.9526679515838623\n",
      "471 iterations took 3.723611831665039\n",
      "481 iterations took 3.5184953212738037\n",
      "491 iterations took 3.8328771591186523\n"
     ]
    }
   ],
   "source": [
    "train_sample_generator = VOC_import.get_train_sample()\n",
    "test_sample_generator = VOC_import.get_val_sample()\n",
    "\n",
    "times = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 500, 10):\n",
    "    clk = time.time()\n",
    "    input_data = np.random.random((1, 224, 224, 3)).astype(np.float32)\n",
    "    input_rois = np.zeros((i,4))\n",
    "\n",
    "    for x in range(1):\n",
    "        learning_rate = .00008\n",
    "\n",
    "\n",
    "        with tf.device(\"/{}:0\".format(device)):\n",
    "            sess.run(cls_prob, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                        rois_in:input_rois, num_rois_tf:len(input_rois)})\n",
    "\n",
    "\n",
    "\n",
    "    dt = time.time() - clk\n",
    "    print(\"{} iterations took {}\".format( i, dt ))\n",
    "    times.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6d80200278>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d802d4cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 500, 10), times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data, input_rois, input_classes = get_inputs(\"train\")\n",
    "input_rois.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig,ax1 = plt.subplots(1,1)\n",
    "ax2 = ax1.twinx()\n",
    "#ax3 = ax1.twinx()\n",
    "\n",
    "clk = time.time()\n",
    "\n",
    "\n",
    "while(True):\n",
    "    learning_rate = .00008\n",
    "\n",
    "    input_data, input_rois, input_classes = get_inputs(\"train\")\n",
    "    \n",
    "    if i % 100 == 10:\n",
    "        \n",
    "        print(\"running iteration {}. last iteration took {}\".format(i, time.time()-clk))\n",
    "        clk = time.time()\n",
    "        loss = sess.run(cross_entropy_loss, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                    y_:input_classes, rois_in:input_rois})\n",
    "        \n",
    "        ax1.cla()\n",
    "        ax2.cla()\n",
    "        #ax3.cla()\n",
    "        ax1.plot(runningMeanFast(np.asarray(stats)[:, 1], 100), \"b\")\n",
    "        ax2.plot(runningMeanFast(np.asarray(stats)[:, 0], 100), \"r\")\n",
    "        ax2.plot(runningMeanFast(np.asarray(stats)[:, 3], 100), \"green\")\n",
    "        #ax3.plot(np.asarray(stats)[:, 2], \"black\")\n",
    "        ax1.set_ylabel('loss', color = \"b\")\n",
    "        ax2.set_ylabel(\"top_k_percent\", color=\"r\")\n",
    "        #ax3.set_ylabel(\"learning_rate\", color=\"black\")\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    elif i % 5 == 0:\n",
    "        with tf.device(\"/{}:0\".format(device)):\n",
    "            train_stats = sess.run([top_k_percent, cross_entropy_loss, opt_op], feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                        y_:input_classes, rois_in:input_rois, num_rois_tf:len(input_rois)})\n",
    "            \n",
    "            input_data, input_rois, input_classes = get_inputs(\"test\")\n",
    "            test_stats = sess.run([top_k_percent], feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                        y_:input_classes, rois_in:input_rois, num_rois_tf:len(input_rois)})\n",
    "            \n",
    "            \n",
    "            stats.append(train_stats[:-1]+[learning_rate]+test_stats)\n",
    "    \n",
    "    else:\n",
    "        with tf.device(\"/{}:0\".format(device)):\n",
    "            sess.run(opt_op, feed_dict={learning_rate_tf:learning_rate, input_data_tensor:input_data, \n",
    "                                        y_:input_classes, rois_in:input_rois, num_rois_tf:len(input_rois)})\n",
    "\n",
    "    \n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save stats and weights\n",
    "import pickle\n",
    "out = sess.run([W_fc6, W_fc7, b_fc6, b_fc7, W_cls, b_cls])\n",
    "\n",
    "with open(\"saved_weights_2\", \"wb\") as outfile:\n",
    "    pickle.dump(out, outfile)\n",
    "\n",
    "with open(\"train_stats_2\", \"wb\") as outfile:\n",
    "    pickle.dump(stats, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"model_2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
